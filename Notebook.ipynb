{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StudentCopy_Section_2_FakeNews.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3810jvsc74a57bd01367987cc7840cfe11a5e48493d0489ed8a2d67afc5da873c4c87b7776f6181c","display_name":"Python 3.8.10 64-bit ('venv': venv)"}},"cells":[{"cell_type":"markdown","metadata":{"id":"gVgIxW-YPeQH"},"source":["# Fake News Classification\n","\n","\n","### Connect Colab to VSCode\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install kora -q\n","from kora import jupyter\n","jupyter.start(lab=True)\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"source":["## Import Libraries"],"cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qT8bCpXGr2nO"},"source":["import tqdm\n","import importlib\n","#@title Run this code to get started\n","imports = {\n","    'pandas':'pd',\n","    'numpy': 'np',\n","    'matplotlib.pyplot': 'plt',\n","    'seaborn': 'sns',\n","    'sklearn':None,\n","    'string':None,\n","    'nltk':None,\n","    'spacy':None,\n","    'wordcloud':None,\n","    'sys':None,\n","    'os':None}\n","\n","print(\"Importing libraries\")\n","for name in tqdm.tqdm(imports):\n","    try:\n","        alias = imports[name] or name\n","        globals()[alias] = __import__(name)\n","    except ImportError:\n","        print(f\"Failed importing {name}\")\n","\n","# import math\n","# import os\n","# import numpy as np\n","# import pandas as pd\n","\n","# import pickle\n","\n","# import requests, io, zipfile\n","\n","# Download class resources...\n","\n","basepath = './dataset'\n","#basepath = 'drive/MyDrive/Notebooks/Fake_news_data'\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","\n","\n","pd.options.mode.chained_assignment = None"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/11 [00:00<?, ?it/s]Importing libraries\n","100%|██████████| 11/11 [00:09<00:00,  1.18it/s]\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Importing NLP\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\lolzc\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\lolzc\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["print(\"Importing NLP\")\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from spacy.lang.en.stop_words import STOP_WORDS\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","\n","from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.metrics import accuracy_score\n","#!python -m spacy download en_core_web_md\n","import en_core_web_md\n","text_to_nlp = en_core_web_md.load()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Load Data\n","fake_data = pd.read_csv(os.path.join(basepath, 'Fake.csv'))\n","true_data = pd.read_csv(os.path.join(basepath, 'True.csv'))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["datapoints: 44898\n% fake: 0.5229854336496058\nReal 21417\n"]}],"source":["# Format the data\n","fake_data['fake'] = 1.0\n","true_data['fake'] = 0.0\n","\n","# Normalize the dataset\n"," \n","# Convert the date column into machine-readable\n","# def date(val):\n","#     datet : datetime.datetime = parser.parse(val)\n","#     return [datet.year, datet.month, datet.day]\n","\n","lf = len(fake_data)\n","lt = len(true_data)\n","\n","print(f'datapoints: {lt+lf}')\n","print(f'% fake: {lf / (lt + lf)}')\n","print(f'Real {lt}')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n","dataset = pd.concat([fake_data, true_data])"]},{"source":["# Dataset Views"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Topics:\n\t\n\tMiddle-east\n\tGovernment News\n\tpoliticsNews\n\tworldnews\n\tpolitics\n\tleft-news\n\tUS_News\n\tNews\n"]},{"output_type":"execute_result","data":{"text/plain":["                                               title  \\\n","0   Donald Trump Sends Out Embarrassing New Year’...   \n","1   Drunk Bragging Trump Staffer Started Russian ...   \n","2   Sheriff David Clarke Becomes An Internet Joke...   \n","3   Trump Is So Obsessed He Even Has Obama’s Name...   \n","4   Pope Francis Just Called Out Donald Trump Dur...   \n","\n","                                                text subject  \\\n","0  Donald Trump just couldn t wish all Americans ...    News   \n","1  House Intelligence Committee Chairman Devin Nu...    News   \n","2  On Friday, it was revealed that former Milwauk...    News   \n","3  On Christmas day, Donald Trump announced that ...    News   \n","4  Pope Francis used his annual Christmas Day mes...    News   \n","\n","                date  fake  \n","0  December 31, 2017   1.0  \n","1  December 31, 2017   1.0  \n","2  December 30, 2017   1.0  \n","3  December 29, 2017   1.0  \n","4  December 25, 2017   1.0  "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>fake</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n      <td>Donald Trump just couldn t wish all Americans ...</td>\n      <td>News</td>\n      <td>December 31, 2017</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n      <td>House Intelligence Committee Chairman Devin Nu...</td>\n      <td>News</td>\n      <td>December 31, 2017</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n      <td>On Friday, it was revealed that former Milwauk...</td>\n      <td>News</td>\n      <td>December 30, 2017</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n      <td>On Christmas day, Donald Trump announced that ...</td>\n      <td>News</td>\n      <td>December 29, 2017</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n      <td>Pope Francis used his annual Christmas Day mes...</td>\n      <td>News</td>\n      <td>December 25, 2017</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":7}],"source":["print(\"Topics:\\n\\t\", *list(set(dataset['subject'])), sep='\\n\\t')\n","\n","dataset.head()\n"]},{"source":["### Generate Word cloud for fake/real news"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fake = True\n","print(\"Fake news Word cloud\")\n","news_text = ''\n","for t in dataset[dataset['fake'] == fake]['text'].values: # form field cell\n","    news_text += t + ' '\n","    \n","wordcloud = WordCloud()    \n","wordcloud.generate_from_text(news_text)\n","plt.figure(figsize=(14,7))\n","plt.imshow(wordcloud, interpolation='bilinear')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fake = False\n","print(\"Real news Word cloud\")\n","news_text = ''\n","for t in dataset[dataset['fake'] == fake]['text'].values: # form field cell\n","    news_text += t + ' '\n","    \n","wordcloud = WordCloud()    \n","wordcloud.generate_from_text(news_text)\n","plt.figure(figsize=(14,7))\n","plt.imshow(wordcloud, interpolation='bilinear')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fake = True\n","print(\"Fake news Title cloud\")\n","news_text = ''\n","for t in dataset[dataset['fake'] == fake]['title'].values: # form field cell\n","    news_text += t + ' '\n","    \n","wordcloud = WordCloud()    \n","wordcloud.generate_from_text(news_text)\n","plt.figure(figsize=(14,7))\n","plt.imshow(wordcloud, interpolation='bilinear')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fake = False\n","print(\"True news Title cloud\")\n","news_text = ''\n","for t in dataset[dataset['fake'] == fake]['title'].values: # form field cell\n","    news_text += t + ' '\n","    \n","wordcloud = WordCloud()    \n","wordcloud.generate_from_text(news_text)\n","plt.figure(figsize=(14,7))\n","plt.imshow(wordcloud, interpolation='bilinear')"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'spacy.tokens.doc.Doc' object has no attribute 'vectors'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m<ipython-input-73-45b168fdc05c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtext_to_nlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"burger alphabet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'vectors'"]}],"source":["\n"]},{"source":["## Prepare data for NLP"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# SKIP\n","# if not \"text_to_nlp\" in globals():\n","#     print(\"Loading NLP converter\")\n","#     text_to_nlp = en_core_web_md.load() #Prepare Spacy\n","# print(\"Tokenizing text\")\n","\n","\n","# x_word2vec = np.zeros((len(dataset),), dtype=object)\n","# i = 0\n","# for text in tqdm.tqdm(dataset['text']):\n","#     x_word2vec[i] = text_to_nlp(text) # Array of tokens, passed to model\n","#     i += 1\n","\n","\n","# # print(\"Tokenizing titles\")\n","# # x_titlevec = np.zeros((len(dataset),), dtype=object)\n","# # i = 0\n","# # for text in tqdm.tqdm(dataset['title']):\n","# #     x_titlevec[i] = text_to_nlp(text) # Array of tokens, passed to model\n","# #     i += 1\n","# # x_titlevec = np.array(x_word2vec)"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["__name__ : 57 B\n__doc__ : 113 B\n__package__ : 16 B\n__loader__ : 16 B\n__spec__ : 16 B\n__builtin__ : 72 B\n__builtins__ : 72 B\n_ih : 776 B\n_oh : 232 B\n_dh : 96 B\nIn : 776 B\nOut : 232 B\nget_ipython : 64 B\nexit : 48 B\nquit : 48 B\n_ : 51 B\n__ : 51 B\n___ : 51 B\nsys : 72 B\nos : 72 B\n_i : 722 B\n_ii : 102 B\n_iii : 270 B\n_i1 : 1036 B\ntqdm : 72 B\nimportlib : 72 B\nimports : 640 B\nname : 51 B\nalias : 51 B\npd : 72 B\nnp : 72 B\nplt : 72 B\nsns : 72 B\nsklearn : 72 B\nstring : 72 B\nnltk : 72 B\nspacy : 72 B\nwordcloud : 72 B\nbasepath : 58 B\nprecision_recall_fscore_support : 136 B\naccuracy_score : 136 B\nconfusion_matrix : 136 B\n_i2 : 755 B\nstopwords : 48 B\nWordNetLemmatizer : 1064 B\nword_tokenize : 136 B\ntrain_test_split : 136 B\nclassification_report : 136 B\n_exit_code : 16 B\nen_core_web_md : 72 B\ntext_to_nlp : 48 B\n_i3 : 621 B\ndatetime : 72 B\nparser : 72 B\n_i4 : 724 B\n_i5 : 120 B\n_i6 : 756 B\n_i7 : 621 B\ndate : 136 B\nlf : 28 B\nlt : 28 B\n_i8 : 724 B\nx_word2vec : 359280 B\ni : 28 B\ntext : 1387 B\n_i9 : 120 B\n_i10 : 214 B\n_i11 : 218 B\nl : 28 B\nr : 28 B\nm : 28 B\n_i12 : 218 B\n_i13 : 218 B\n_i14 : 214 B\n_i15 : 218 B\n_i16 : 724 B\n_i17 : 120 B\n_i18 : 718 B\n_i19 : 120 B\n_i20 : 955 B\n_i21 : 1009 B\n_i22 : 134 B\n_i23 : 146 B\n_i24 : 146 B\n_i25 : 174 B\n_i26 : 134 B\n_i27 : 146 B\n_i28 : 242 B\n_i29 : 243 B\n_i30 : 243 B\n_i31 : 243 B\n_i32 : 241 B\npickle : 72 B\nf : 168 B\n_i33 : 154 B\n_i34 : 153 B\nzarr : 72 B\n_i35 : 165 B\n_i36 : 165 B\n_i37 : 213 B\nnumcodecs : 72 B\n_i38 : 226 B\n_i39 : 239 B\n_i40 : 172 B\n_i41 : 245 B\n_i42 : 247 B\n_i43 : 250 B\n_i44 : 248 B\n_i45 : 257 B\n_i46 : 257 B\n_i47 : 245 B\n_i48 : 146 B\n_i49 : 158 B\n_i50 : 139 B\n_i51 : 134 B\n_i52 : 146 B\n_i53 : 218 B\n_i54 : 134 B\n_i55 : 155 B\n_i56 : 156 B\n_i57 : 218 B\n_i58 : 85 B\n_i59 : 85 B\n_i60 : 93 B\ntf : 72 B\n_i61 : 101 B\nkeras : 72 B\n_i62 : 1792 B\n_i63 : 1851 B\nragged_concat : 136 B\nMultiKernel1D : 896 B\nNewsNet : 896 B\n_i64 : 2569 B\n_i65 : 637 B\nfake_data : 69875829 B\ntrue_data : 86833062 B\n_i66 : 635 B\ndataset : 153842558 B\n_i67 : 2569 B\n_i68 : 186 B\n_i69 : 189 B\n_i70 : 2571 B\n_i71 : 189 B\nnewsNet : 48 B\noptimizer : 48 B\n_i72 : 756 B\nSTOP_WORDS : 32984 B\nWordCloud : 1064 B\nCountVectorizer : 1064 B\nLogisticRegression : 1064 B\n_i73 : 87 B\n_i74 : 140 B\n_i75 : 145 B\n_i76 : 121 B\n_i77 : 152 B\nDocBin : 1192 B\n_i78 : 157 B\n_i79 : 152 B\n_i80 : 270 B\nx_train : 269480 B\nx_test : 89896 B\ny_train : 538784 B\ny_test : 179616 B\n_i81 : 102 B\n_i82 : 722 B\n_i83 : 146 B\n"]}],"source":["# Memory mapper\n","print(*[f'{k} : {sys.getsizeof(v)} B' for (k, v) in globals().items()], sep='\\n')"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["# x_word2vec = np.concat(np.load(os.path.join(\"E:\\\\Desktop\\\\Dataset\", 'word_vecs1')), np.load(os.path.join(\"E:\\\\Desktop\\\\Dataset\", 'word_vecs')) # Necessary!!!"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["44896\n"]}],"source":["# # Search for first zero\n","# l = 0\n","# r = len(x_word2vec)-1\n","# m = 0\n","# while l < r:\n","#     m = (l + m + 1)//2\n","#     if x_word2vec[m] == 0:\n","#         r = m\n","#     else:\n","#         l = m+1\n","# print(m)"]},{"source":["# Load ML libraries\n","\n"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras"]},{"source":["\n","def ragged_concat(arr, axis=1):\n","    return tf.RaggedTensor.from_row_lengths(tf.concat(arr, axis=axis), row_lengths=tuple(len(i) for i in arr))\n","\n","conv3 = keras.layers.Conv1D(8, kernel_size=3, padding='same')\n","conv2 = keras.layers.Conv1D(4, kernel_size=2, padding='same')\n","conv5 = keras.layers.Conv1D(4, kernel_size=4, padding='same')\n"],"cell_type":"markdown","metadata":{}},{"source":["l = [conv5(tf.zeros((1, 12, 300))), conv3(tf.zeros((1, 12, 300))), conv2(tf.zeros((1, 12, 300)))]\n","# Shape is (Batch, Word Vecs, Word Vec size)\n","# 'same' padding fixes the word vec size\n","# We have different filter sizes\n","# (Last one)\n","tf.concat(l, 2)"],"cell_type":"markdown","metadata":{}},{"source":["## Build the model"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["\n","class MultiKernel1D(keras.layers.Layer):\n","    \"\"\"Supports using multiple kernel sizes for convoltion on text\"\"\"\n","    def __init__(self, filters:tuple=(100, 100, 100), kernels:tuple=(3,4,5), input_shape=(None, 300)):\n","        super(MultiKernel1D, self).__init__()\n","        self.kernels = [keras.layers.Conv1D(filter, kernel, input_shape=input_shape, padding='same') for (filter, kernel) in zip(filters, kernels)]\n","\n","    def call(self, inputs, training=None):\n","        # Call each of the kernels\n","        # Output should be like\n","        # Input shape is a tensor of size (A, 300)\n","        # Which means a variable vector of 300-vectors\n","        # Which represent word embeddings\n","\n","        # Each convolution outputs a vector that is (A, filters)\n","        # We need to combine them into a ragged tensor\n","        # [\n","        #   C1: [F1: [?, ?, ...], F2: [?, ?, ...], ...]\n","        #   C2: [F1: [?, ?, ...], F2: [?, ?, ...], ...]\n","        #   C3: [F1: [?, ?, ...], F2: [?, ?, ...], ...]\n","        # ]\n","        # 3 dimensions, ragged middle vector\n","        return tf.concat([kernel(inputs) for kernel in self.kernels], -1)\n","\n","        #     Conv 2\n","        #  /        /F1\n","        # Conv 1     F2\n","        # 0 | F1 F2 ... F3\n","        # 1 | F1 F2  F4 \n","        # 2 | F1 F2  /\n","        # 3 | F1 F2 /\n","        # 4 | F1 F2\n","        # So 3-d Tensor, or 4-d with batches\n","\n","\n","        \n","\n","class NewsNet(keras.Model):\n","    def __init__(self):\n","        super(NewsNet, self).__init__()\n","        self.kernels = MultiKernel1D()\n","\n","        self.sequential = keras.layers.LSTM(30)\n","        self.dense10 = keras.layers.Dense(10)\n","        self.predictor = keras.layers.Dense(1, activation='sigmoid') # [Real, Fake]\n","    \n","    def call(self, x, training=None):\n","\n","        x = self.kernels(x)\n","        x = self.sequential(x)\n","        x = self.dense10(x)\n","        return self.predictor(x)[0]\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["newsNet = NewsNet()\n","optimizer = keras.optimizers.Adam(learning_rate=5e-5)\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(dataset['text'], dataset['fake'].to_numpy(), test_size=0.07)\n","\n","loss_fn = keras.losses.MeanSquaredError()"]},{"cell_type":"markdown","metadata":{"id":"MA0H-ezT3A3-"},"source":["\n","# Training the model\n","\n"]},{"cell_type":"code","execution_count":81,"metadata":{"tags":["outputPrepend"]},"outputs":[{"output_type":"stream","name":"stderr","text":[" 30700: 0.0000\n","9702it [54:38,  2.86it/s]Training loss (for one batch) at step 30750: 0.0000\n","9753it [54:56,  2.91it/s]Training loss (for one batch) at step 30800: 0.0000\n","9804it [55:12,  4.16it/s]Training loss (for one batch) at step 30850: 0.0013\n","9853it [55:25,  4.36it/s]Training loss (for one batch) at step 30900: 0.0000\n","9903it [55:52,  3.51it/s]Training loss (for one batch) at step 30950: 0.0000\n","9953it [56:07,  3.19it/s]Training loss (for one batch) at step 31000: 0.0000\n","10001it [56:26,  4.55it/s]Training loss (for one batch) at step 31050: 0.0000\n","10051it [56:40,  3.82it/s]Training loss (for one batch) at step 31100: 0.0000\n","10102it [56:54,  4.52it/s]Training loss (for one batch) at step 31150: 0.0000\n","10152it [57:10,  3.05it/s]Training loss (for one batch) at step 31200: 0.0000\n","10202it [57:29,  3.79it/s]Training loss (for one batch) at step 31250: 0.0000\n","10252it [57:52,  2.21s/it]Training loss (for one batch) at step 31300: 0.0000\n","10303it [58:07,  4.33it/s]Training loss (for one batch) at step 31350: 0.0000\n","10353it [58:23,  2.61it/s]Training loss (for one batch) at step 31400: 0.0000\n","10402it [58:38,  3.29it/s]Training loss (for one batch) at step 31450: 0.0000\n","10453it [58:53,  4.56it/s]Training loss (for one batch) at step 31500: 0.0000\n","10503it [59:09,  3.93it/s]Training loss (for one batch) at step 31550: 0.0000\n","10553it [59:25,  3.53it/s]Training loss (for one batch) at step 31600: 0.0004\n","10602it [59:41,  3.28it/s]Training loss (for one batch) at step 31650: 0.0000\n","10652it [1:00:02,  4.43it/s]Training loss (for one batch) at step 31700: 0.0000\n","10702it [1:00:21,  2.22it/s]Training loss (for one batch) at step 31750: 0.0000\n","10753it [1:00:41,  2.50it/s]Training loss (for one batch) at step 31800: 0.0000\n","10802it [1:01:05,  1.23it/s]Training loss (for one batch) at step 31850: 0.0000\n","10852it [1:01:21,  2.94it/s]Training loss (for one batch) at step 31900: 0.0099\n","10902it [1:01:39,  1.70it/s]Training loss (for one batch) at step 31950: 0.9951\n","10952it [1:01:54,  2.18it/s]Training loss (for one batch) at step 32000: 0.0004\n","11002it [1:02:11,  2.89it/s]Training loss (for one batch) at step 32050: 0.0001\n","11053it [1:02:46,  4.10it/s]Training loss (for one batch) at step 32100: 0.0028\n","11102it [1:03:01,  2.97it/s]Training loss (for one batch) at step 32150: 0.0000\n","11154it [1:03:17,  4.92it/s]Training loss (for one batch) at step 32200: 0.0000\n","11202it [1:03:32,  2.58it/s]Training loss (for one batch) at step 32250: 0.0000\n","11252it [1:03:51,  2.48it/s]Training loss (for one batch) at step 32300: 0.0000\n","11301it [1:04:05,  3.39it/s]Training loss (for one batch) at step 32350: 0.0003\n","11353it [1:04:24,  3.35it/s]Training loss (for one batch) at step 32400: 0.0000\n","11402it [1:04:41,  2.88it/s]Training loss (for one batch) at step 32450: 0.0000\n","11452it [1:04:56,  2.88it/s]Training loss (for one batch) at step 32500: 0.0013\n","11503it [1:05:12,  4.41it/s]Training loss (for one batch) at step 32550: 0.0000\n","11552it [1:05:26,  3.54it/s]Training loss (for one batch) at step 32600: 0.0000\n","11602it [1:05:50,  2.09it/s]Training loss (for one batch) at step 32650: 0.0000\n","11651it [1:06:11,  2.72it/s]Training loss (for one batch) at step 32700: 0.0000\n","11702it [1:06:27,  2.33it/s]Training loss (for one batch) at step 32750: 0.0000\n","11752it [1:06:45,  1.78it/s]Training loss (for one batch) at step 32800: 0.0000\n","11803it [1:07:06,  3.31it/s]Training loss (for one batch) at step 32850: 0.0000\n","11852it [1:07:25,  1.24it/s]Training loss (for one batch) at step 32900: 0.0005\n","11902it [1:07:41,  3.15it/s]Training loss (for one batch) at step 32950: 0.0000\n","11952it [1:08:05,  3.05it/s]Training loss (for one batch) at step 33000: 0.0001\n","12002it [1:08:21,  3.14it/s]Training loss (for one batch) at step 33050: 0.0000\n","12052it [1:08:41,  2.98it/s]Training loss (for one batch) at step 33100: 0.0025\n","12102it [1:09:00,  2.72it/s]Training loss (for one batch) at step 33150: 0.0000\n","12152it [1:09:17,  2.16it/s]Training loss (for one batch) at step 33200: 0.0000\n","12201it [1:09:34,  2.51it/s]Training loss (for one batch) at step 33250: 0.0001\n","12252it [1:09:50,  3.63it/s]Training loss (for one batch) at step 33300: 0.0000\n","12302it [1:10:06,  3.76it/s]Training loss (for one batch) at step 33350: 0.0000\n","12352it [1:10:23,  3.38it/s]Training loss (for one batch) at step 33400: 0.0000\n","12402it [1:10:42,  2.32it/s]Training loss (for one batch) at step 33450: 0.0000\n","12452it [1:11:02,  3.76it/s]Training loss (for one batch) at step 33500: 0.0000\n","12502it [1:11:22,  2.34it/s]Training loss (for one batch) at step 33550: 0.0016\n","12552it [1:11:37,  3.34it/s]Training loss (for one batch) at step 33600: 0.0000\n","12603it [1:11:53,  4.44it/s]Training loss (for one batch) at step 33650: 0.0001\n","12652it [1:12:09,  3.26it/s]Training loss (for one batch) at step 33700: 0.0001\n","12703it [1:12:26,  3.20it/s]Training loss (for one batch) at step 33750: 0.0000\n","12753it [1:12:41,  2.90it/s]Training loss (for one batch) at step 33800: 0.0000\n","12803it [1:13:04,  3.82it/s]Training loss (for one batch) at step 33850: 0.0000\n","12852it [1:13:22,  1.94it/s]Training loss (for one batch) at step 33900: 0.0001\n","12902it [1:13:42,  2.15it/s]Training loss (for one batch) at step 33950: 0.0027\n","12954it [1:13:57,  4.55it/s]Training loss (for one batch) at step 34000: 0.0000\n","13003it [1:14:13,  3.66it/s]Training loss (for one batch) at step 34050: 0.0000\n","13052it [1:14:28,  3.64it/s]Training loss (for one batch) at step 34100: 0.0000\n","13102it [1:14:44,  2.64it/s]Training loss (for one batch) at step 34150: 0.0000\n","13152it [1:15:04,  3.22it/s]Training loss (for one batch) at step 34200: 0.0000\n","13202it [1:15:20,  3.14it/s]Training loss (for one batch) at step 34250: 0.0000\n","13252it [1:15:40,  2.20it/s]Training loss (for one batch) at step 34300: 0.6432\n","13303it [1:15:59,  3.50it/s]Training loss (for one batch) at step 34350: 0.0000\n","13352it [1:16:32,  2.49it/s]Training loss (for one batch) at step 34400: 0.0000\n","13402it [1:16:52,  3.80it/s]Training loss (for one batch) at step 34450: 0.0000\n","13452it [1:17:10,  2.77it/s]Training loss (for one batch) at step 34500: 0.0001\n","13501it [1:17:24,  5.01it/s]Training loss (for one batch) at step 34550: 0.0003\n","13552it [1:17:38,  3.54it/s]Training loss (for one batch) at step 34600: 0.0000\n","13602it [1:17:54,  3.85it/s]Training loss (for one batch) at step 34650: 0.0000\n","13652it [1:18:09,  2.70it/s]Training loss (for one batch) at step 34700: 0.0000\n","13703it [1:18:25,  3.86it/s]Training loss (for one batch) at step 34750: 0.0001\n","13752it [1:18:41,  1.91it/s]Training loss (for one batch) at step 34800: 0.0000\n","13802it [1:18:56,  2.78it/s]Training loss (for one batch) at step 34850: 0.0000\n","13853it [1:19:24,  2.63it/s]Training loss (for one batch) at step 34900: 0.0000\n","13902it [1:19:43,  2.54it/s]Training loss (for one batch) at step 34950: 0.0000\n","13953it [1:19:58,  3.76it/s]Training loss (for one batch) at step 35000: 0.0000\n","14002it [1:20:24,  1.39s/it]Training loss (for one batch) at step 35050: 0.0000\n","14052it [1:20:38,  2.99it/s]Training loss (for one batch) at step 35100: 0.0000\n","14102it [1:20:52,  3.60it/s]Training loss (for one batch) at step 35150: 0.0001\n","14152it [1:21:15,  1.50s/it]Training loss (for one batch) at step 35200: 0.0000\n","14202it [1:21:30,  3.02it/s]Training loss (for one batch) at step 35250: 0.0000\n","14252it [1:21:44,  3.32it/s]Training loss (for one batch) at step 35300: 0.0002\n","14302it [1:22:00,  2.40it/s]Training loss (for one batch) at step 35350: 0.0000\n","14352it [1:22:18,  1.15it/s]Training loss (for one batch) at step 35400: 0.0000\n","14402it [1:22:33,  4.29it/s]Training loss (for one batch) at step 35450: 0.0001\n","14452it [1:22:49,  3.93it/s]Training loss (for one batch) at step 35500: 0.0000\n","14502it [1:23:05,  3.90it/s]Training loss (for one batch) at step 35550: 0.0000\n","14554it [1:23:21,  6.51it/s]Training loss (for one batch) at step 35600: 0.0000\n","14602it [1:23:36,  4.12it/s]Training loss (for one batch) at step 35650: 0.0000\n","14652it [1:23:53,  5.08it/s]Training loss (for one batch) at step 35700: 0.0000\n","14703it [1:24:06,  4.35it/s]Training loss (for one batch) at step 35750: 0.0000\n","14752it [1:24:23,  3.17it/s]Training loss (for one batch) at step 35800: 0.0000\n","14802it [1:24:57,  1.84it/s]Training loss (for one batch) at step 35850: 0.0000\n","14851it [1:25:10,  3.89it/s]Training loss (for one batch) at step 35900: 0.0279\n","14901it [1:25:28,  2.23it/s]Training loss (for one batch) at step 35950: 0.0000\n","14951it [1:25:41,  3.95it/s]Training loss (for one batch) at step 36000: 0.0000\n","15002it [1:25:58,  2.26it/s]Training loss (for one batch) at step 36050: 0.0000\n","15053it [1:26:13,  3.30it/s]Training loss (for one batch) at step 36100: 0.0000\n","15101it [1:26:48,  1.90it/s]Training loss (for one batch) at step 36150: 0.0279\n","15152it [1:27:05,  1.86it/s]Training loss (for one batch) at step 36200: 0.0000\n","15202it [1:27:22,  2.96it/s]Training loss (for one batch) at step 36250: 0.0000\n","15252it [1:27:38,  3.50it/s]Training loss (for one batch) at step 36300: 0.0000\n","15302it [1:27:53,  2.86it/s]Training loss (for one batch) at step 36350: 0.0000\n","15352it [1:28:09,  4.06it/s]Training loss (for one batch) at step 36400: 0.0000\n","15402it [1:28:24,  2.60it/s]Training loss (for one batch) at step 36450: 0.0000\n","15452it [1:28:39,  3.26it/s]Training loss (for one batch) at step 36500: 0.0000\n","15502it [1:28:54,  2.72it/s]Training loss (for one batch) at step 36550: 0.0000\n","15552it [1:29:27,  3.56it/s]Training loss (for one batch) at step 36600: 0.0000\n","15602it [1:29:40,  2.88it/s]Training loss (for one batch) at step 36650: 0.0001\n","15654it [1:29:58,  5.62it/s]Training loss (for one batch) at step 36700: 0.0000\n","15703it [1:30:13,  4.70it/s]Training loss (for one batch) at step 36750: 0.0000\n","15752it [1:30:29,  2.85it/s]Training loss (for one batch) at step 36800: 0.0000\n","15802it [1:30:47,  2.22it/s]Training loss (for one batch) at step 36850: 0.0000\n","15852it [1:31:04,  4.01it/s]Training loss (for one batch) at step 36900: 0.0000\n","15902it [1:31:19,  3.72it/s]Training loss (for one batch) at step 36950: 0.0002\n","15952it [1:31:35,  3.72it/s]Training loss (for one batch) at step 37000: 0.0000\n","16002it [1:31:51,  3.39it/s]Training loss (for one batch) at step 37050: 0.0000\n","16052it [1:32:04,  3.77it/s]Training loss (for one batch) at step 37100: 0.0000\n","16103it [1:32:17,  3.49it/s]Training loss (for one batch) at step 37150: 0.0000\n","16153it [1:32:34,  3.32it/s]Training loss (for one batch) at step 37200: 0.0000\n","16202it [1:32:49,  4.12it/s]Training loss (for one batch) at step 37250: 0.0000\n","16252it [1:33:06,  5.76it/s]Training loss (for one batch) at step 37300: 0.0000\n","16302it [1:33:22,  2.90it/s]Training loss (for one batch) at step 37350: 0.0000\n","16352it [1:33:36,  3.41it/s]Training loss (for one batch) at step 37400: 0.0000\n","16403it [1:33:54,  2.93it/s]Training loss (for one batch) at step 37450: 0.0003\n","16454it [1:34:10,  4.17it/s]Training loss (for one batch) at step 37500: 0.0000\n","16501it [1:34:26,  4.10it/s]Training loss (for one batch) at step 37550: 0.0000\n","16552it [1:34:38,  6.17it/s]Training loss (for one batch) at step 37600: 0.0000\n","16601it [1:34:59,  1.20s/it]Training loss (for one batch) at step 37650: 0.0000\n","16652it [1:35:14,  4.21it/s]Training loss (for one batch) at step 37700: 0.0002\n","16702it [1:35:28,  4.60it/s]Training loss (for one batch) at step 37750: 0.0000\n","16752it [1:35:49,  1.76it/s]Training loss (for one batch) at step 37800: 0.0000\n","16802it [1:36:02,  3.60it/s]Training loss (for one batch) at step 37850: 0.0000\n","16852it [1:36:15,  5.13it/s]Training loss (for one batch) at step 37900: 0.0000\n","16902it [1:36:30,  4.42it/s]Training loss (for one batch) at step 37950: 0.0000\n","16952it [1:36:47,  4.10it/s]Training loss (for one batch) at step 38000: 0.0000\n","17003it [1:37:05,  4.12it/s]Training loss (for one batch) at step 38050: 0.0000\n","17052it [1:37:20,  2.80it/s]Training loss (for one batch) at step 38100: 0.0000\n","17102it [1:37:35,  4.25it/s]Training loss (for one batch) at step 38150: 0.0000\n","17152it [1:37:53,  2.18it/s]Training loss (for one batch) at step 38200: 0.0000\n","17203it [1:38:09,  4.70it/s]Training loss (for one batch) at step 38250: 0.0000\n","17252it [1:38:25,  3.55it/s]Training loss (for one batch) at step 38300: 0.0000\n","17302it [1:38:38,  3.03it/s]Training loss (for one batch) at step 38350: 0.0000\n","17352it [1:38:53,  4.55it/s]Training loss (for one batch) at step 38400: 0.0000\n","17403it [1:39:07,  3.60it/s]Training loss (for one batch) at step 38450: 0.0000\n","17452it [1:39:21,  3.41it/s]Training loss (for one batch) at step 38500: 0.0000\n","17502it [1:39:38,  3.11it/s]Training loss (for one batch) at step 38550: 0.0001\n","17552it [1:39:57,  4.59it/s]Training loss (for one batch) at step 38600: 0.0000\n","17602it [1:40:12,  4.50it/s]Training loss (for one batch) at step 38650: 0.0000\n","17652it [1:40:27,  4.25it/s]Training loss (for one batch) at step 38700: 0.0000\n","17703it [1:40:42,  5.04it/s]Training loss (for one batch) at step 38750: 0.0000\n","17752it [1:40:56,  3.66it/s]Training loss (for one batch) at step 38800: 0.0000\n","17802it [1:41:12,  2.65it/s]Training loss (for one batch) at step 38850: 0.0000\n","17853it [1:41:27,  4.63it/s]Training loss (for one batch) at step 38900: 0.0000\n","17901it [1:41:43,  2.24it/s]Training loss (for one batch) at step 38950: 0.0000\n","17952it [1:41:57,  3.14it/s]Training loss (for one batch) at step 39000: 0.0000\n","18004it [1:42:14,  3.33it/s]Training loss (for one batch) at step 39050: 0.0000\n","18052it [1:42:28,  2.61it/s]Training loss (for one batch) at step 39100: 0.0000\n","18103it [1:42:43,  3.88it/s]Training loss (for one batch) at step 39150: 0.0000\n","18151it [1:42:57,  5.69it/s]Training loss (for one batch) at step 39200: 0.0000\n","18203it [1:43:16,  4.41it/s]Training loss (for one batch) at step 39250: 0.0000\n","18253it [1:43:39,  3.61it/s]Training loss (for one batch) at step 39300: 0.0000\n","18303it [1:44:00,  3.76it/s]Training loss (for one batch) at step 39350: 0.0000\n","18352it [1:44:39,  2.15it/s]Training loss (for one batch) at step 39400: 0.0000\n","18402it [1:44:52,  6.29it/s]Training loss (for one batch) at step 39450: 0.1668\n","18452it [1:45:10,  2.99it/s]Training loss (for one batch) at step 39500: 0.0000\n","18502it [1:45:27,  3.02it/s]Training loss (for one batch) at step 39550: 0.0000\n","18554it [1:45:42,  4.46it/s]Training loss (for one batch) at step 39600: 0.0000\n","18603it [1:45:56,  3.47it/s]Training loss (for one batch) at step 39650: 0.0000\n","18653it [1:46:12,  3.58it/s]Training loss (for one batch) at step 39700: 0.0000\n","18702it [1:46:32,  3.35it/s]Training loss (for one batch) at step 39750: 0.0000\n","18752it [1:46:47,  3.55it/s]Training loss (for one batch) at step 39800: 0.0000\n","18802it [1:47:03,  3.43it/s]Training loss (for one batch) at step 39850: 0.0000\n","18852it [1:47:16,  2.23it/s]Training loss (for one batch) at step 39900: 0.0000\n","18903it [1:47:31,  4.51it/s]Training loss (for one batch) at step 39950: 0.0002\n","18952it [1:47:46,  2.41it/s]Training loss (for one batch) at step 40000: 0.0000\n","19001it [1:48:06,  1.97it/s]Training loss (for one batch) at step 40050: 0.0000\n","19052it [1:48:21,  3.94it/s]Training loss (for one batch) at step 40100: 0.0000\n","19102it [1:48:37,  2.83it/s]Training loss (for one batch) at step 40150: 0.0000\n","19151it [1:48:54,  2.42it/s]Training loss (for one batch) at step 40200: 0.0180\n","19201it [1:49:10,  3.56it/s]Training loss (for one batch) at step 40250: 0.0004\n","19252it [1:49:32,  3.29it/s]Training loss (for one batch) at step 40300: 0.0000\n","19302it [1:49:47,  4.76it/s]Training loss (for one batch) at step 40350: 0.0024\n","19352it [1:50:04,  3.25it/s]Training loss (for one batch) at step 40400: 0.0000\n","19403it [1:50:20,  4.54it/s]Training loss (for one batch) at step 40450: 0.0002\n","19452it [1:50:34,  2.76it/s]Training loss (for one batch) at step 40500: 0.0000\n","19502it [1:50:52,  4.03it/s]Training loss (for one batch) at step 40550: 0.0000\n","19553it [1:51:06,  5.30it/s]Training loss (for one batch) at step 40600: 0.0000\n","19602it [1:51:20,  2.61it/s]Training loss (for one batch) at step 40650: 0.0000\n","19652it [1:51:36,  3.25it/s]Training loss (for one batch) at step 40700: 0.0000\n","19702it [1:51:57,  3.99it/s]Training loss (for one batch) at step 40750: 0.0001\n","19752it [1:52:16,  1.99it/s]Training loss (for one batch) at step 40800: 0.0000\n","19802it [1:52:41,  1.72it/s]Training loss (for one batch) at step 40850: 0.0013\n","19852it [1:52:58,  4.45it/s]Training loss (for one batch) at step 40900: 0.0000\n","19904it [1:53:17,  6.26it/s]Training loss (for one batch) at step 40950: 0.0000\n","19952it [1:53:55,  3.05it/s]Training loss (for one batch) at step 41000: 0.0002\n","20003it [1:54:17,  3.84it/s]Training loss (for one batch) at step 41050: 0.0164\n","20052it [1:54:31,  3.97it/s]Training loss (for one batch) at step 41100: 0.0000\n","20102it [1:54:46,  3.51it/s]Training loss (for one batch) at step 41150: 0.0000\n","20152it [1:55:04,  3.66it/s]Training loss (for one batch) at step 41200: 0.0000\n","20202it [1:55:20,  3.46it/s]Training loss (for one batch) at step 41250: 0.0256\n","20252it [1:55:36,  3.34it/s]Training loss (for one batch) at step 41300: 0.0000\n","20303it [1:55:52,  5.15it/s]Training loss (for one batch) at step 41350: 0.0000\n","20353it [1:56:09,  3.66it/s]Training loss (for one batch) at step 41400: 0.0000\n","20402it [1:56:26,  4.01it/s]Training loss (for one batch) at step 41450: 0.0003\n","20452it [1:56:41,  4.35it/s]Training loss (for one batch) at step 41500: 0.0000\n","20502it [1:56:58,  2.98it/s]Training loss (for one batch) at step 41550: 0.0000\n","20552it [1:57:15,  2.84it/s]Training loss (for one batch) at step 41600: 0.0015\n","20602it [1:57:32,  3.15it/s]Training loss (for one batch) at step 41650: 0.0000\n","20653it [1:57:48,  3.49it/s]Training loss (for one batch) at step 41700: 0.0000\n","20703it [1:58:01,  4.31it/s]Training loss (for one batch) at step 41750: 0.0001\n","20752it [1:58:26,  2.40it/s]Training loss (for one batch) at step 41800: 0.0000\n","20803it [1:58:42,  4.29it/s]Training loss (for one batch) at step 41850: 0.0001\n","20852it [1:58:55,  3.36it/s]Training loss (for one batch) at step 41900: 0.0000\n","20903it [1:59:12,  3.53it/s]Training loss (for one batch) at step 41950: 0.0000\n","20951it [1:59:27,  6.86it/s]Training loss (for one batch) at step 42000: 0.0042\n","21002it [1:59:55,  2.00it/s]Training loss (for one batch) at step 42050: 0.0006\n","21052it [2:00:09,  3.25it/s]Training loss (for one batch) at step 42100: 0.0001\n","21102it [2:00:25,  4.78it/s]Training loss (for one batch) at step 42150: 0.0000\n","21153it [2:00:40,  4.66it/s]Training loss (for one batch) at step 42200: 0.0000\n","21202it [2:00:55,  3.11it/s]Training loss (for one batch) at step 42250: 0.0000\n","21252it [2:01:10,  2.69it/s]Training loss (for one batch) at step 42300: 0.0000\n","21302it [2:01:27,  3.11it/s]Training loss (for one batch) at step 42350: 0.0000\n","21352it [2:01:42,  5.33it/s]Training loss (for one batch) at step 42400: 0.0000\n","21403it [2:02:01,  4.35it/s]Training loss (for one batch) at step 42450: 0.0000\n","21451it [2:02:15,  4.62it/s]Training loss (for one batch) at step 42500: 0.0015\n","21502it [2:02:30,  4.02it/s]Training loss (for one batch) at step 42550: 0.0000\n","21552it [2:02:46,  4.09it/s]Training loss (for one batch) at step 42600: 0.0000\n","21602it [2:03:07,  1.03s/it]Training loss (for one batch) at step 42650: 0.0000\n","21652it [2:03:20,  3.14it/s]Training loss (for one batch) at step 42700: 0.0000\n","21701it [2:03:38,  2.86it/s]Training loss (for one batch) at step 42750: 0.0000\n","21751it [2:03:51,  3.12it/s]Training loss (for one batch) at step 42800: 0.0000\n","21802it [2:04:05,  3.87it/s]Training loss (for one batch) at step 42850: 0.0000\n","21853it [2:04:22,  3.69it/s]Training loss (for one batch) at step 42900: 0.0004\n","21902it [2:04:37,  4.06it/s]Training loss (for one batch) at step 42950: 0.0000\n","21953it [2:04:52,  2.60it/s]Training loss (for one batch) at step 43000: 0.0000\n","22002it [2:05:08,  3.59it/s]Training loss (for one batch) at step 43050: 0.0000\n","22053it [2:05:21,  4.54it/s]Training loss (for one batch) at step 43100: 0.0000\n","22102it [2:05:35,  4.33it/s]Training loss (for one batch) at step 43150: 0.0000\n","22152it [2:05:55,  3.18it/s]Training loss (for one batch) at step 43200: 0.0001\n","22187it [2:06:06,  2.93it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-81-cbf634fe8ae9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# Iterate over the batches of the dataset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mx_batch_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_to_nlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfake\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    993\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 995\u001b[1;33m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    996\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m                 \u001b[1;31m# This typically happens if a component is not initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \"\"\"\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\spacy\\ml\\tb_framework.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     step_model = ParserStepModel(\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\spacy\\ml\\parser_model.pyx\u001b[0m in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\layers\\with_array.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList2d\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\layers\\with_array.py\u001b[0m in \u001b[0;36m_list_forward\u001b[1;34m(model, Xs, is_train)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray1i\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mXf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mYf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_dXf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdYs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList2d\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\layers\\residual.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0md_output\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackprop_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lolzc\\Desktop\\AICamp\\venv\\lib\\site-packages\\thinc\\layers\\maxout.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"W\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape2f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnO\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape1f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnO\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape3f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["## Note: Rerunning this cell uses the same model variables\n","global printed\n","model = newsNet\n","printed = False\n","def print_remove(s, *a, **k):\n","    global printed\n","    if (printed):\n","        print('\\r' + s, *a, **k)\n","    else:\n","        print(s, *a, **k)\n","\n","@tf.function(input_signature=(tf.TensorSpec(shape=[1, None, 300], dtype=tf.float32), tf.TensorSpec(shape=(1), dtype=tf.float32)))\n","def train_step(x, y):\n","    with tf.GradientTape() as tape:\n","        logits = model(x, training=True)\n","        loss_value = loss_fn(y, logits)\n","    grads = tape.gradient(loss_value, model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","    train_acc_metric.update_state(y, logits)\n","    return loss_value\n","\n","\n","train_acc_metric = keras.metrics.AUC()\n","val_acc_metric = keras.metrics.BinaryAccuracy()\n","@tf.function(input_signature=(tf.TensorSpec(shape=[1, None, 300], dtype=tf.float32), tf.TensorSpec(shape=(1,1), dtype=tf.float32)))\n","def test_step(x, y):\n","    val_logits = model(x, training=False)\n","    val_acc_metric.update_state(y, val_logits)\n","\n","\n","# Keep results for plotting\n","train_loss_results = []\n","train_accuracy_results = []\n","\n","import time\n","step = 21049 # Resume training\n","epochs = 20\n","for epoch in range(epochs):\n","    print(\"\\nStart of epoch %d\" % (epoch,))\n","    start_time = time.time()\n","    # Iterate over the batches of the dataset.\n","    for text, fake in tqdm.tqdm(zip(x_train, y_train)):\n","        x_batch_train = tf.constant([[np.array(x.vector) for x in text_to_nlp(text)]])\n","        loss_value = train_step(x_batch_train, [fake])\n","\n","        # Log every 50 batches.\n","        if step % 50 == 0:\n","            print_remove(\n","                \"Training loss (for one batch) at step %d: %.4f\"\n","                % (step, float(loss_value))\n","            )\n","        step += 1\n","\n","    # Display metrics at the end of each epoch.\n","    train_acc = train_acc_metric.result()\n","    print_remove(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","\n","    # Reset training metrics at the end of each epoch\n","    train_acc_metric.reset_states()\n","\n","    # Run a validation loop at the end of each epoch.\n","    step = 0\n","    for text, fake in tqdm.tqdm(zip(x_test, y_test)):\n","        x_batch_val = tf.constant([[x.vector for x in text_to_nlp(text)]])\n","        y_batch_val = np.reshape([fake], newshape=(1,1))\n","        test_step(x_batch_val, y_batch_val)\n","\n","    val_acc = val_acc_metric.result()\n","    val_acc_metric.reset_states()\n","    print_remove(\"Validation acc: %.4f\" % (float(val_acc),))\n","    print_remove(\"Time taken: %.2fs\" % (time.time() - start_time))\n","    step=0\n","\n"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(0.0022363365, shape=(), dtype=float32)\n"]}],"source":["idx = np.random.randint(0, len(true_data))\n","\n","res = model(tf.constant([[x.vector for x in text_to_nlp(true_data.at[idx, 'text'])]]))\n","print(res[0])"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, conv1d_12_layer_call_fn, conv1d_12_layer_call_and_return_conditional_losses, conv1d_13_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, conv1d_12_layer_call_fn, conv1d_12_layer_call_and_return_conditional_losses, conv1d_13_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: news_classifier\\assets\n","INFO:tensorflow:Assets written to: news_classifier\\assets\n"]}],"source":["# Save the model\n","model.save('news_classifier') "]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["100it [00:20,  5.31it/s]Validation acc: 1.0000\n","200it [00:38,  6.72it/s]Validation acc: 1.0000\n","301it [00:57,  6.55it/s]Validation acc: 1.0000\n","401it [01:13,  7.09it/s]Validation acc: 0.9975\n","500it [01:31,  5.25it/s]Validation acc: 0.9980\n","601it [01:50,  5.02it/s]Validation acc: 0.9967\n","700it [02:05,  5.92it/s]Validation acc: 0.9971\n","800it [02:21,  7.57it/s]Validation acc: 0.9975\n","900it [02:41,  3.70it/s]Validation acc: 0.9978\n","1001it [02:57,  5.50it/s]Validation acc: 0.9980\n","1100it [03:11,  6.67it/s]Validation acc: 0.9973\n","1201it [03:26,  8.72it/s]Validation acc: 0.9975\n","1300it [03:44,  7.59it/s]Validation acc: 0.9977\n","1399it [04:00,  8.72it/s]Validation acc: 0.9964\n","1503it [04:16,  9.17it/s]Validation acc: 0.9967\n","1600it [04:33,  5.53it/s]Validation acc: 0.9962\n","1701it [04:48,  5.88it/s]Validation acc: 0.9959\n","1799it [05:04,  8.10it/s]Validation acc: 0.9961\n","1901it [05:23,  6.29it/s]Validation acc: 0.9963\n","2003it [05:39,  8.34it/s]Validation acc: 0.9960\n","2100it [05:56,  2.66it/s]Validation acc: 0.9962\n","2202it [06:14,  8.07it/s]Validation acc: 0.9964\n","2300it [06:30,  7.64it/s]Validation acc: 0.9965\n","2402it [06:46,  9.58it/s]Validation acc: 0.9967\n","2501it [07:01,  6.82it/s]Validation acc: 0.9968\n","2599it [07:17,  5.59it/s]Validation acc: 0.9969\n","2701it [07:33,  5.99it/s]Validation acc: 0.9970\n","2798it [07:50,  5.29it/s]Validation acc: 0.9971\n","2900it [08:09,  1.88it/s]Validation acc: 0.9972\n","3001it [08:28,  5.58it/s]Validation acc: 0.9973\n","3101it [08:48,  6.16it/s]Validation acc: 0.9974\n","3143it [08:55,  5.87it/s]\n"]}],"source":["step = 0\n","for text, fake in tqdm.tqdm(zip(x_test, y_test)):\n","    x_batch_val = tf.constant([[x.vector for x in text_to_nlp(text)]])\n","    y_batch_val = np.reshape([fake], newshape=(1,1))\n","    test_step(x_batch_val, y_batch_val)\n","    step += 1\n","    if step % 100 == 0:\n","        print_remove(\"Validation acc: %.4f\" % (float(val_acc_metric.result()),))"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation acc: 0.9975\nTime taken: 8131.30s\n"]}],"source":["val_acc = val_acc_metric.result()\n","print_remove(\"Validation acc: %.4f\" % (float(val_acc),))\n","print_remove(\"Time taken: %.2fs\" % (time.time() - start_time))"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["val_acc_metric.reset_states()"]},{"cell_type":"markdown","metadata":{"id":"WchEBxFeA46-"},"source":["## Exercise 4 \n","\n"]},{"cell_type":"code","metadata":{"id":"xv_PHkE6346w"},"source":["# train_y_pred = model.predict([[x.vector for x in text_to_nlp(y)] for y in x_test])\n","# print('Train accuracy', accuracy_score(y_test, train_y_pred))\n","\n","for text, fake in tqdm.tqdm(zip(x_test, y_test)):\n","    x_batch_val = tf.constant([[x.vector for x in text_to_nlp(text)]])\n","    y_batch_val = np.reshape([fake], newshape=(1,1))\n","    test_step(x_batch_val, y_batch_val)\n","\n","val_acc = val_acc_metric.result()\n","val_acc_metric.reset_states()\n","print_remove(\"Validation acc: %.4f\" % (float(val_acc),))\n","print_remove(\"Time taken: %.2fs\" % (time.time() - start_time))"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["3143it [09:46,  5.36it/s]Validation acc: 0.0000\n","Time taken: 50641.49s\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"ylD5OWTZoCz2"},"source":["We can see that we are not doing very well, but we are doing better than 50%. We can do the same for the val data to see how we are doing on unseen data, which is more valuable for us if we want to make predictions on new websites. Fill in the code below to evaluate val accuracy!"]},{"cell_type":"markdown","metadata":{"id":"Hq6sGGVHobjo"},"source":["We appear to be doing a bit worse on the val data, not much better than chance. To better understand the performance of our binary classification model, we should seek to better understand the mistakes that it is making. Specifically, when our model makes a mistake (about 40% of the time), are these mistakes false negatives or false positives?"]},{"cell_type":"markdown","metadata":{"id":"0A_HLeiz9IlH"},"source":["## Confusion Matrix "]},{"cell_type":"markdown","metadata":{"id":"VeWbCvMa8rhg"},"source":["To answer these questions, we produce and analyze the confusion matrix. The confusion matrix is a matrix that shows the following:\n","\n","![Confusion Matrix](https://cdn-images-1.medium.com/max/1600/1*Z54JgbS4DUwWSknhDCvNTQ.png)\n","\n","where the terms mean\n","\n","* TP (True Positive) = You predicted positive (fake in our case, since fake has a label of 1) and it’s true.\n","* FP (False Positive) = You predicted positive and it’s false.\n","* FN (False Negative) = You predicted negative and it’s false.\n","* TN (True Negative) = You predicted negative and it’s true.\n","\n","\n","###Common Metrics\n","\n","From the confusion matrix, we can extract commonly used metrics like precision (TP/(TP + FP)) and recall (TP/(TP + FN)). \n","\n","* Precision quantifies how often the things we classify as positive are actually positive. For our task, this measures what fraction of the sites we classify as fake are actually fake. \n","* Recall quantifies what fraction of actually positive examples we classify as positive. In our case, this is the fraction of fake news websites that we actually identify as fake.\n","\n","Finally, a useful score to summarize both precision and recall is the F-1 score. This is just a simple function (the harmonic mean) of precision and recall, shown in the summary below:\n","\n","<img src=\"https://datascience103579984.files.wordpress.com/2019/04/capture3-24.png\" width=\"400\" height=\"200\"></img>"]},{"cell_type":"markdown","metadata":{"id":"pftTwsCvE8Lt"},"source":["##Exercise 5 |  Using the Confusion Matrix "]},{"cell_type":"markdown","metadata":{"id":"tc9BxsQ-GYOo"},"source":["Run the cell below to create the confusion matrix for our own model. "]},{"cell_type":"code","metadata":{"id":"M9aYm4oqsL6P"},"source":["print('Confusion matrix:')\n","print(confusion_matrix(y_train, train_y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q5Of0ZHsHZ0C"},"source":["A Confusion Matrix can quickly tell you how well your model is doing. The primary way to figure this out is to calculate the Error Rate. \n","\n","The Error Rate is:   (FP) + (FN)) / (TP + FP + FN + TN).\n","\n","This is just all the false predictions (False Negative + False Positive) divided by all the predictions added together.  \n","\n","Use the Confusion Matrix we just created to calculate the Error Rate for our model. "]},{"cell_type":"code","metadata":{"id":"Bo0Bej9z_xcq"},"source":["### YOUR CODE HERE ###\n","\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ac9XXM9XsU0"},"source":["## Exercise 6"]},{"cell_type":"code","metadata":{"id":"gVxJhwhzspF-"},"source":["print(val_y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nh-qi0tvGvFH"},"source":["We can see that we have many false negatives, and not as many false positives. Why is this the case? If we print out *val_y_pred*, we can see that our model is mostly predicting 0's (websites are real)."]},{"cell_type":"markdown","metadata":{"id":"fa5GCh7eG7OU"},"source":["What fraction of predictions in *val_y_pred* are 1's? Hint: you may find *np.mean* useful."]},{"cell_type":"code","metadata":{"id":"pStoI4cLfKDv"},"source":["### YOUR CODE HERE ###\n","\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eQdhOeigtmCp"},"source":["Why so many 0's? The only information we are giving our model is its domain name extension. It's natural that the model would learn that websites with \".biz\" extensions are unlikely to be reliable news websites, but it is still the case that most websites in the dataset (fake and real) have \".com\" extensions. Thus, our model will misclassify many fake news websites with \".com\" extensions as real. "]},{"cell_type":"code","metadata":{"id":"tHQTv6L98uno"},"source":["prf = precision_recall_fscore_support(val_y, val_y_pred)\n","\n","print('Precision:', prf[0][1])\n","print('Recall:', prf[1][1])\n","print('F-Score:', prf[2][1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vw9xDPTsruaB"},"source":["Again, the precision and recall metrics suggest that when we classify a website as fake, we are usually right, but we are not doing great at classifying these websites as fake frequently enough."]},{"cell_type":"markdown","metadata":{"id":"vyJC74B7ALAy"},"source":["##Using Keywords for a Stronger Baseline "]},{"cell_type":"markdown","metadata":{"id":"_3lY7pMkAPpX"},"source":["The key problem with our model in its current state is that it simply does not have enough information. This should not be a surprise–it was pretty unlikely in the first place that domain name extensions would be enough. If you like, feel free to add a few more extensions in the “featurizer” above and re-run all the code for evaluation–you'll find it doesn't make much of a difference.\n","Where can we get more information about webpages? From the HTML! Remember that the HTML contains all of the text and structure of a webpage. If we cleverly choose features from the HTML to feed into our logistic regression model, we will drastically improve our performance. We saw yesterday that probing hypotheses related to the counts of hypotheses words produced interesting results, and we will continue in this direction today to produce a model that leverages these differences in word frequencies.\n"]},{"cell_type":"markdown","metadata":{"id":"TyRp6ooJAnng"},"source":["## Exercise 7: Instructor-Led Discussion on Better Input Features\n"]},{"cell_type":"markdown","metadata":{"id":"L4jjZ5HF35K0"},"source":["\n","The below code introduces a better featurizer that counts the number of keywords (normalized using the *log* function) in the HTML. Normalizing the counts is a trick that prevents the featurized values from becoming too extreme. Read the code and make sure you understand what it is doing. Then add \"sports\" and \"finance\" as additional keywords to expand our model.\n","\n","**Run the below code and discuss what it is doing as a class. Add in additional keywords to further expand our model as you see fit.**\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sk_BBflEAuX3"},"source":["##Exercise 8"]},{"cell_type":"markdown","metadata":{"id":"bgWx3s7UxDue"},"source":["\n","\n","Let's run and evaluate the above featurizer. Add in code to fit the model, compute train accuracy, val accuracy, val confusion matrix, and val precision, recall, and F1-Score, just as before."]},{"cell_type":"code","metadata":{"id":"fxEIPqn1f1iQ"},"source":["train_X, train_y, feature_descriptions = prepare_data(train_data, keyword_featurizer)\n","val_X, val_y, feature_descriptions = prepare_data(val_data, keyword_featurizer)\n","\n","print('Number of features per example:', len(train_X[0]))\n","print('Feature descriptions:')\n","print(feature_descriptions)\n","print()\n","  \n","baseline_model = LogisticRegression()\n","\n","### YOUR CODE HERE ###\n","\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1l9Jq6CzwWOt"},"source":["## Interpreting our Model\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_hTNITBgB871"},"source":["### Instructor-Led Discussion: Interpreting Input Variables"]},{"cell_type":"markdown","metadata":{"id":"43z3A67xB4Qu"},"source":["As mentioned earlier, a key motivation for using a simpler model is interpretability.\n","\n","We've learned that the prediction of a logistic regression classifier is just the output of a multiplication with model weights, followed by a non-linear transformation (sigmoid). Because the sigmoid function is always increasing (monotonic) on its domain (see below), we know that if the dot product (or multiplication of vectors) between model weights and input features is large, then the output prediction will be closer to 1. If the dot product is small, then the output prediction will be closer to 0.\n","\n","![Sigmoid](https://cdn-images-1.medium.com/max/2400/1*RqXFpiNGwdiKBWyLJc_E7g.png)\n","\n","Thus, the weights corresponding to features tell us whether the features are important in the classification. If the weight corresponding to the feature \".net domain\" has a large positive value, then websites with \".net\" domains are more likely to be classified as fake (since fake has label 1). If it has a large negative value, then these websites are more likely to be classified as real. If it has value close to 0, then the feature may not be useful (at least, it may not be useful given that the other features are present).\n"]},{"cell_type":"markdown","metadata":{"id":"nqIKnF6fCgnP"},"source":["###Using Feature Descriptions"]},{"cell_type":"markdown","metadata":{"id":"0G8LwtG2Cj9u"},"source":["Let's see what weights our model learned. The code below uses *feature_descriptions* and the weights, or coefficients, of the model and sorts them in ascending order."]},{"cell_type":"code","metadata":{"id":"QHcJkqd4zic8"},"source":["sorted(zip(feature_descriptions, baseline_model.coef_[0].tolist()), key=lambda x: x[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qfIAQeg5zpRL"},"source":["## Exercise 9\n","\n","Answer the following questions:\n","\n","* What features have positive weight (most predictive of being fake)? What does that indicate?\n","* Which ones have negative weight (most predictive of being real)? What does that indicate?\n","* Which ones have close to 0 weight? \n","* Are there any feature weights that surprise you? \n","* Try coming up with explanations for why the feature weights are the way they are. Does this help you come up with new feature ideas? (~15 minutes)"]},{"cell_type":"code","metadata":{"id":"gnYk7Vp_YiSO"},"source":["'''\n","- \n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"082Dut9agst6"},"source":["## Instructor-Led Discussion: Final Interpretation of Inputs"]},{"cell_type":"markdown","metadata":{"id":"gfQvDlNAYjAa"},"source":["##Exercise 10 |  Final Baseline\n","\n","Finally, play around with the last few cells, adding more keywords and domain names to see how the results change. Note that \"keywords\" can be a variety of things: English words, English phrases (spaces are allowed), HTML tags, and any other string present in HTML. Also notice how the weights on different features vary–you may observe some interesting effects. When you are done, run the cell below to run evaluations again!"]},{"cell_type":"code","metadata":{"id":"19rbiCbuP8iq"},"source":["train_y_pred = baseline_model.predict(train_X)\n","print('Train accuracy', accuracy_score(train_y, train_y_pred))\n","\n","val_y_pred = baseline_model.predict(val_X)\n","print('Val accuracy', accuracy_score(val_y, val_y_pred))\n","\n","print('Confusion matrix:')\n","print(confusion_matrix(val_y, val_y_pred))\n","\n","prf = precision_recall_fscore_support(val_y, val_y_pred)\n","\n","print('Precision:', prf[0][1])\n","print('Recall:', prf[1][1])\n","print('F-Score:', prf[2][1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U6aOTjSX0_yj"},"source":["Congratulations on completing this notebook. Looking at the results of our final baseline, you may be surprised this approach is working at all–after all, our model is still barely looking at the content of websites. We will further explore the issue of modeling the content of websites tomorrow, but as a result of our efforts today, we now know that we can make progress with a relatively simple approach!"]}]}